{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import streamlit as st\n",
    "from folium.plugins import MarkerCluster\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import geopandas\n",
    "from streamlit_folium import folium_static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     7,
     12,
     16,
     21,
     84,
     139,
     206
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#functions    \n",
    "    \n",
    "    def streamlit_settings():\n",
    "        st.set_page_config(layout='wide')\n",
    "        st.cache(allow_output_mutation=True)\n",
    "        return None\n",
    "\n",
    "    def get_data(path):\n",
    "        data = pd.read_csv(path)\n",
    "        return data\n",
    "\n",
    "    st.cache(allow_output_mutation=True)\n",
    "    def get_geofile(url):\n",
    "        geofile = geopandas.read_file(url)\n",
    "        return geofile\n",
    "\n",
    "    def set_feature(data):\n",
    "        #add new features\n",
    "        data['price_m2'] = data['price']/data['sqft_lot']\n",
    "        return data\n",
    "\n",
    "    def overview_data(data):\n",
    "        #Data Overview\n",
    "        f_attributes = st.sidebar.multiselect('Enter columns', data.columns)\n",
    "        f_zipcode = st.sidebar.multiselect('Enter zipcode',\n",
    "                                           data['zipcode'].unique())\n",
    "        st.title('Data Overview')\n",
    "\n",
    "        if (f_zipcode != []) & (f_attributes != []):\n",
    "            data = data.loc[data['zipcode'].isin(f_zipcode), f_attributes]\n",
    "\n",
    "        elif (f_zipcode != []) & (f_attributes == []):\n",
    "            data = data.loc[data['zipcode'].isin(f_zipcode), :]\n",
    "\n",
    "        elif (f_zipcode == []) & (f_attributes != []):\n",
    "            data = data.loc[:, f_attributes]\n",
    "\n",
    "        else:\n",
    "            data = data.copy()\n",
    "\n",
    "        st.dataframe(data)\n",
    "\n",
    "        c1, c2 = st.beta_columns((2, 1))\n",
    "\n",
    "        # average metrics:\n",
    "        df1 = data[['id', 'zipcode']].groupby('zipcode').count().reset_index()\n",
    "        df2 = data[['price', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df3 = data[['sqft_living', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df4 = data[['price_m2', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "\n",
    "        # merge\n",
    "        m1 = pd.merge(df1, df2, on='zipcode', how='inner')\n",
    "        m2 = pd.merge(m1, df3, on='zipcode', how='inner')\n",
    "        m3 = pd.merge(m2, df4, on='zipcode', how='inner')\n",
    "\n",
    "        m3.columns = ['zipcode', 'total houses', 'price', 'sqft living', 'price/m2']\n",
    "\n",
    "        c1.header('Average Values')\n",
    "        c1.dataframe(m3, height=600)\n",
    "\n",
    "        # descriptive stats\n",
    "        num_attributes = data.select_dtypes(['int64', 'float64'])\n",
    "        media = pd.DataFrame(num_attributes.apply(np.mean))\n",
    "        mediana = pd.DataFrame(num_attributes.apply(np.median))\n",
    "        std = pd.DataFrame(num_attributes.apply(np.std))\n",
    "        max_ = pd.DataFrame(num_attributes.apply(np.max))\n",
    "        min_ = pd.DataFrame(num_attributes.apply(np.min))\n",
    "\n",
    "        df1 = pd.concat([max_, min_, media, mediana, std], axis=1).reset_index()\n",
    "\n",
    "        df1.columns = ['attributes', 'max', 'min', 'mean', 'median', 'std']\n",
    "\n",
    "        c2.header('Descriptive Statistics')\n",
    "        c2.dataframe(df1, height=800)\n",
    "\n",
    "        st.write(data.head())\n",
    "        # attributes => colunas\n",
    "        # zipcode => linhas\n",
    "\n",
    "        st.write(f_attributes)\n",
    "        st.write(f_zipcode)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def portfolio_density(data, geofile):\n",
    "        #Portfolio Density Plots\n",
    "        st.title('Region Overview')\n",
    "\n",
    "        c1, c2 = st.beta_columns((1, 1))\n",
    "        c1.header('Portfolio Density')\n",
    "\n",
    "        df = data.sample(10)\n",
    "\n",
    "        # Base map - Folium\n",
    "        density_map = folium.Map(location=[data['lat'].mean(), data['long'].mean()],\n",
    "                                 default_zoom_start=15)\n",
    "\n",
    "        marker_cluster = MarkerCluster().add_to(density_map)\n",
    "\n",
    "        for name, row in df.iterrows():\n",
    "            folium.Marker([row['lat'], row['long']],\n",
    "                          popup='Price R${0} on: {1}, Features: {2} sqft, {3} bedrooms, {4} bathrooms, {5} year_built'.format(\n",
    "                              row['price'],\n",
    "                              row['date'],\n",
    "                              row['sqft_living'],\n",
    "                              row['bedrooms'],\n",
    "                              row['bathrooms'],\n",
    "                              row['year_built'])).add_to(marker_cluster)\n",
    "\n",
    "        with c1:\n",
    "            folium_static(density_map)\n",
    "\n",
    "        # Region Price Map\n",
    "        c2.header('Price Density')\n",
    "\n",
    "        df = data[['price', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df.colums = ['ZIP', 'PRICE']\n",
    "\n",
    "        df = df.sample(10)\n",
    "\n",
    "        geofile = geofile[geofile['ZIP'].isin(df['ZIP'].tolist())]\n",
    "\n",
    "        region_price_map = folium.Map(location=[data['lat'].mean(), data['long'].mean()],\n",
    "                                      default_zoom_start=15)\n",
    "\n",
    "        region_price_map.choropleth(data=df,\n",
    "                                    geo_data=geofiles,\n",
    "                                    columns=['ZIP', 'PRICE'],\n",
    "                                    key_on='feature.properties.ZIP',\n",
    "                                    fill_color='YlOrRd',\n",
    "                                    fill_opacity=0.7,\n",
    "                                    line_opacity=0.2,\n",
    "                                    legend_name='AVG PRICE')\n",
    "\n",
    "        with c2:\n",
    "            folium_static(region_price_map)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def commercial_distribution(data):\n",
    "        #Houses distribution\n",
    "        st.sidebar.title('Commercial Options')\n",
    "        st.title('Commercial Attributes')\n",
    "\n",
    "        # filters\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        min_year_built = int(data['yr_built'].min())\n",
    "        max_year_built = int(data['yr_built'].max())\n",
    "\n",
    "        st.sidebar.subheader('Select Max Year Built')\n",
    "        f_year_built = st.sidebar.slider('Year Built', min_year_built,\n",
    "                                         max_year_built, min_year_built)\n",
    "\n",
    "        st.header('Average price per Year Built')\n",
    "        # ---------------Average Price per Year\n",
    "\n",
    "        df = data.loc[data['yr_built'] < f_year_built]\n",
    "        df = data[['yr_built', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "        fig = px.line(df, x='yr_built', y='price')\n",
    "\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # ---------------Average Price per Day\n",
    "        st.header('Average Price per day')\n",
    "        st.sidebar.subheader('Select Max Date')\n",
    "\n",
    "        # filter\n",
    "        min_date = datetime.strptime(data['date'].min(), '%Y-%m-%d')\n",
    "        max_date = datetime.strptime(data['date'].max(), '%Y-%m-%d')\n",
    "\n",
    "        f_date = st.sidebar.slider('Date', min_date,\n",
    "                                   max_date, min_date)\n",
    "\n",
    "        # data filtering\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        df = data.loc[data['date'] < f_date]\n",
    "        df = data[['date', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "        # plot\n",
    "        fig = px.line(df, x='date', y='price')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # ------------------------------------\n",
    "        # Histograma\n",
    "        st.header('Price Distribution')\n",
    "        st.sidebar.subheader('Select Max Price')\n",
    "\n",
    "        # filter\n",
    "        min_price = int(data['price'].min())\n",
    "        max_price = int(data['price'].max())\n",
    "        avg_price = int(data['price'].mean())\n",
    "\n",
    "        # filter\n",
    "        f_price = st.sidebar.slider('Price', min_price,\n",
    "                                    max_price, avg_price)\n",
    "\n",
    "        # data filtering\n",
    "        df = data.loc[data['price'] < f_price]\n",
    "\n",
    "        # plot\n",
    "        fig = px.histogram(df, x='price', nbins=50)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def attributes_distribution(data):\n",
    "        #all attributes\n",
    "        st.sidebar.title('Attributes Options')\n",
    "        st.title('House Attributes')\n",
    "\n",
    "        # filters\n",
    "        f_bedrooms = st.sidebar.selectbox('Max Number Bedrooms',\n",
    "                                          sorted(set(data['bedrooms'].unique())))\n",
    "\n",
    "        f_bathrooms = st.sidebar.selectbox('Max Number Bathrooms',\n",
    "                                           sorted(set(data['bathrooms'].unique())))\n",
    "\n",
    "        c1, c2 = st.beta_columns(2)\n",
    "\n",
    "        # Houses per bedrooms\n",
    "        c1.header('Houses per bedrooms')\n",
    "        df = data[data['bedrooms'] < f_bedrooms]\n",
    "        fig = px.histogram(df, x='bedrooms', nbins=19)\n",
    "        c1.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # Houses per bathrooms\n",
    "        c2.header('Houses per bathrooms')\n",
    "        df = data[data['bathrooms'] < f_bathrooms]\n",
    "        fig = px.histogram(df, x='bathrooms', nbins=19)\n",
    "        c2.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # filter\n",
    "        f_floors = st.sidebar.selectbox('Max number of floor',\n",
    "                                        sorted(set(data['floors'].unique())))\n",
    "\n",
    "        c1, c2 = st.beta_columns(2)\n",
    "        # Houses per floors\n",
    "        c1.header('Houses per floor')\n",
    "        df = data[data['floors'] < f_floors]\n",
    "\n",
    "        # plot\n",
    "        fig = px.histogram(df, x='floors', nbins=19)\n",
    "        c1.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # House per water view\n",
    "        c2.header('Houses per water view')\n",
    "        if f_waterview:\n",
    "            df = data[data['waterfront'] == 1]\n",
    "\n",
    "        else:\n",
    "            df = data.copy()\n",
    "\n",
    "        # plot\n",
    "        fig = px.histogram(df, x='waterfront', nbins=10)\n",
    "        c2.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "streamlit_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#getting the original dataframe\n",
    "path = 'C:\\\\Users\\\\joaoa\\\\Documents\\\\DSprojects\\\\Git\\\\repos\\\\DataScience_Em_Producao\\\\House_Rocket\\\\kc_house_data.csv'\n",
    "data = get_data(path)\n",
    "\n",
    "# get geofile\n",
    "path2 = 'C:\\\\Users\\\\joaoa\\\\Documents\\\\DSprojects\\\\Git\\\\repos\\\\DataScience_Em_Producao\\\\House_Rocket\\\\Zip_Codes.geojson'\n",
    "geofile = get_geofile(url)\n",
    "\n",
    "#original url for .json download\n",
    "url = 'https://opendata.arcgis.com/datasets/83fc2e72903343aabff6de8cb445b81c_2.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#transformation\n",
    "data = set_feature(data)\n",
    "\n",
    "overview_data(data)\n",
    "\n",
    "portfolio_density(data, geofile)\n",
    "\n",
    "commercial_distribution(data)\n",
    "\n",
    "attributes_distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "   \n",
    "    #ETL\n",
    "    #extraction\n",
    "\n",
    "    #transformation\n",
    "    \n",
    "    #loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:36:56.458078Z",
     "start_time": "2021-04-04T00:36:56.442444Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import streamlit as st\n",
    "from folium.plugins import MarkerCluster\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import geopandas\n",
    "from streamlit_folium import folium_static\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 0.1 Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:37:04.538839Z",
     "start_time": "2021-04-04T00:37:04.431437Z"
    },
    "code_folding": [
     0,
     2,
     11,
     16,
     21,
     25,
     30,
     93,
     148,
     215
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#functions    \n",
    "    \n",
    "def settings():\n",
    "        plt.style.use('bmh')\n",
    "        plt.rcParams['figure.figsize']=21,12\n",
    "        plt.rcParams['font.size']=24\n",
    "    \n",
    "        warnings.filterwarnings('ignore')#to ignore that we're dividing by zero\n",
    "    \n",
    "        sns.set()\n",
    "        \n",
    "def streamlit_settings():\n",
    "        st.set_page_config(layout='wide')\n",
    "        st.cache(allow_output_mutation=True)\n",
    "        return None\n",
    "\n",
    "def get_data(path):\n",
    "        data = pd.read_csv(path)\n",
    "        return data\n",
    "\n",
    "st.cache(allow_output_mutation=True)\n",
    "def get_geofile(url):\n",
    "        geofile = geopandas.read_file(url)\n",
    "        return geofile\n",
    "\n",
    "def set_feature(data):\n",
    "        #add new features\n",
    "        data['price_m2'] = data['price']/data['sqft_lot']\n",
    "        return data\n",
    "\n",
    "def overview_data(data):\n",
    "        #Data Overview\n",
    "        f_attributes = st.sidebar.multiselect('Enter columns', data.columns)\n",
    "        f_zipcode = st.sidebar.multiselect('Enter zipcode',\n",
    "                                           data['zipcode'].unique())\n",
    "        st.title('Data Overview')\n",
    "\n",
    "        if (f_zipcode != []) & (f_attributes != []):\n",
    "            data = data.loc[data['zipcode'].isin(f_zipcode), f_attributes]\n",
    "\n",
    "        elif (f_zipcode != []) & (f_attributes == []):\n",
    "            data = data.loc[data['zipcode'].isin(f_zipcode), :]\n",
    "\n",
    "        elif (f_zipcode == []) & (f_attributes != []):\n",
    "            data = data.loc[:, f_attributes]\n",
    "\n",
    "        else:\n",
    "            data = data.copy()\n",
    "\n",
    "        st.dataframe(data)\n",
    "\n",
    "        c1, c2 = st.beta_columns((2, 1))\n",
    "\n",
    "        # average metrics:\n",
    "        df1 = data[['id', 'zipcode']].groupby('zipcode').count().reset_index()\n",
    "        df2 = data[['price', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df3 = data[['sqft_living', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df4 = data[['price_m2', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "\n",
    "        # merge\n",
    "        m1 = pd.merge(df1, df2, on='zipcode', how='inner')\n",
    "        m2 = pd.merge(m1, df3, on='zipcode', how='inner')\n",
    "        m3 = pd.merge(m2, df4, on='zipcode', how='inner')\n",
    "\n",
    "        m3.columns = ['zipcode', 'total houses', 'price', 'sqft living', 'price/m2']\n",
    "\n",
    "        c1.header('Average Values')\n",
    "        c1.dataframe(m3, height=600)\n",
    "\n",
    "        # descriptive stats\n",
    "        num_attributes = data.select_dtypes(['int64', 'float64'])\n",
    "        media = pd.DataFrame(num_attributes.apply(np.mean))\n",
    "        mediana = pd.DataFrame(num_attributes.apply(np.median))\n",
    "        std = pd.DataFrame(num_attributes.apply(np.std))\n",
    "        max_ = pd.DataFrame(num_attributes.apply(np.max))\n",
    "        min_ = pd.DataFrame(num_attributes.apply(np.min))\n",
    "\n",
    "        df1 = pd.concat([max_, min_, media, mediana, std], axis=1).reset_index()\n",
    "\n",
    "        df1.columns = ['attributes', 'max', 'min', 'mean', 'median', 'std']\n",
    "\n",
    "        c2.header('Descriptive Statistics')\n",
    "        c2.dataframe(df1, height=800)\n",
    "\n",
    "        st.write(data.head())\n",
    "        # attributes => colunas\n",
    "        # zipcode => linhas\n",
    "\n",
    "        st.write(f_attributes)\n",
    "        st.write(f_zipcode)\n",
    "\n",
    "        return None\n",
    "\n",
    "def portfolio_density(data, geofile):\n",
    "        #Portfolio Density Plots\n",
    "        st.title('Region Overview')\n",
    "\n",
    "        c1, c2 = st.beta_columns((1, 1))\n",
    "        c1.header('Portfolio Density')\n",
    "\n",
    "        df = data.sample(10)\n",
    "\n",
    "        # Base map - Folium\n",
    "        density_map = folium.Map(location=[data['lat'].mean(), data['long'].mean()],\n",
    "                                 default_zoom_start=15)\n",
    "\n",
    "        marker_cluster = MarkerCluster().add_to(density_map)\n",
    "\n",
    "        for name, row in df.iterrows():\n",
    "            folium.Marker([row['lat'], row['long']],\n",
    "                          popup='Price R${0} on: {1}, Features: {2} sqft, {3} bedrooms, {4} bathrooms, {5} year_built'.format(\n",
    "                              row['price'],\n",
    "                              row['date'],\n",
    "                              row['sqft_living'],\n",
    "                              row['bedrooms'],\n",
    "                              row['bathrooms'],\n",
    "                              row['year_built'])).add_to(marker_cluster)\n",
    "\n",
    "        with c1:\n",
    "            folium_static(density_map)\n",
    "\n",
    "        # Region Price Map\n",
    "        c2.header('Price Density')\n",
    "\n",
    "        df = data[['price', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df.colums = ['ZIP', 'PRICE']\n",
    "\n",
    "        df = df.sample(10)\n",
    "\n",
    "        geofile = geofile[geofile['ZIP'].isin(df['ZIP'].tolist())]\n",
    "\n",
    "        region_price_map = folium.Map(location=[data['lat'].mean(), data['long'].mean()],\n",
    "                                      default_zoom_start=15)\n",
    "\n",
    "        region_price_map.choropleth(data=df,\n",
    "                                    geo_data=geofiles,\n",
    "                                    columns=['ZIP', 'PRICE'],\n",
    "                                    key_on='feature.properties.ZIP',\n",
    "                                    fill_color='YlOrRd',\n",
    "                                    fill_opacity=0.7,\n",
    "                                    line_opacity=0.2,\n",
    "                                    legend_name='AVG PRICE')\n",
    "\n",
    "        with c2:\n",
    "            folium_static(region_price_map)\n",
    "\n",
    "        return None\n",
    "\n",
    "def commercial_distribution(data):\n",
    "        #Houses distribution\n",
    "        st.sidebar.title('Commercial Options')\n",
    "        st.title('Commercial Attributes')\n",
    "\n",
    "        # filters\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        min_year_built = int(data['yr_built'].min())\n",
    "        max_year_built = int(data['yr_built'].max())\n",
    "\n",
    "        st.sidebar.subheader('Select Max Year Built')\n",
    "        f_year_built = st.sidebar.slider('Year Built', min_year_built,\n",
    "                                         max_year_built, min_year_built)\n",
    "\n",
    "        st.header('Average price per Year Built')\n",
    "        # ---------------Average Price per Year\n",
    "\n",
    "        df = data.loc[data['yr_built'] < f_year_built]\n",
    "        df = data[['yr_built', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "        fig = px.line(df, x='yr_built', y='price')\n",
    "\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # ---------------Average Price per Day\n",
    "        st.header('Average Price per day')\n",
    "        st.sidebar.subheader('Select Max Date')\n",
    "\n",
    "        # filter\n",
    "        min_date = datetime.strptime(data['date'].min(), '%Y-%m-%d')\n",
    "        max_date = datetime.strptime(data['date'].max(), '%Y-%m-%d')\n",
    "\n",
    "        f_date = st.sidebar.slider('Date', min_date,\n",
    "                                   max_date, min_date)\n",
    "\n",
    "        # data filtering\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        df = data.loc[data['date'] < f_date]\n",
    "        df = data[['date', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "        # plot\n",
    "        fig = px.line(df, x='date', y='price')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # ------------------------------------\n",
    "        # Histograma\n",
    "        st.header('Price Distribution')\n",
    "        st.sidebar.subheader('Select Max Price')\n",
    "\n",
    "        # filter\n",
    "        min_price = int(data['price'].min())\n",
    "        max_price = int(data['price'].max())\n",
    "        avg_price = int(data['price'].mean())\n",
    "\n",
    "        # filter\n",
    "        f_price = st.sidebar.slider('Price', min_price,\n",
    "                                    max_price, avg_price)\n",
    "\n",
    "        # data filtering\n",
    "        df = data.loc[data['price'] < f_price]\n",
    "\n",
    "        # plot\n",
    "        fig = px.histogram(df, x='price', nbins=50)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        return None\n",
    "\n",
    "def attributes_distribution(data):\n",
    "        #all attributes\n",
    "        st.sidebar.title('Attributes Options')\n",
    "        st.title('House Attributes')\n",
    "\n",
    "        # filters\n",
    "        f_bedrooms = st.sidebar.selectbox('Max Number Bedrooms',\n",
    "                                          sorted(set(data['bedrooms'].unique())))\n",
    "\n",
    "        f_bathrooms = st.sidebar.selectbox('Max Number Bathrooms',\n",
    "                                           sorted(set(data['bathrooms'].unique())))\n",
    "\n",
    "        c1, c2 = st.beta_columns(2)\n",
    "\n",
    "        # Houses per bedrooms\n",
    "        c1.header('Houses per bedrooms')\n",
    "        df = data[data['bedrooms'] < f_bedrooms]\n",
    "        fig = px.histogram(df, x='bedrooms', nbins=19)\n",
    "        c1.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # Houses per bathrooms\n",
    "        c2.header('Houses per bathrooms')\n",
    "        df = data[data['bathrooms'] < f_bathrooms]\n",
    "        fig = px.histogram(df, x='bathrooms', nbins=19)\n",
    "        c2.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # filter\n",
    "        f_floors = st.sidebar.selectbox('Max number of floor',\n",
    "                                        sorted(set(data['floors'].unique())))\n",
    "\n",
    "        c1, c2 = st.beta_columns(2)\n",
    "        # Houses per floors\n",
    "        c1.header('Houses per floor')\n",
    "        df = data[data['floors'] < f_floors]\n",
    "\n",
    "        # plot\n",
    "        fig = px.histogram(df, x='floors', nbins=19)\n",
    "        c1.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # House per water view\n",
    "        c2.header('Houses per water view')\n",
    "        if f_waterview:\n",
    "            df = data[data['waterfront'] == 1]\n",
    "\n",
    "        else:\n",
    "            df = data.copy()\n",
    "\n",
    "        # plot\n",
    "        fig = px.histogram(df, x='waterfront', nbins=10)\n",
    "        c2.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:37:07.202658Z",
     "start_time": "2021-04-04T00:37:07.176492Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "streamlit_settings()\n",
    "settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-04T00:40:57.801Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting the original dataframe\n",
    "path = 'C:\\\\Users\\\\joaoa\\\\Documents\\\\DSprojects\\\\Git\\\\repos\\\\DataScience_Em_Producao\\\\House_Rocket\\\\kc_house_data.csv'\n",
    "df_raw = get_data(path)\n",
    "\n",
    "# get geofile\n",
    "path2 = 'C:\\\\Users\\\\joaoa\\\\Documents\\\\DSprojects\\\\Git\\\\repos\\\\DataScience_Em_Producao\\\\House_Rocket\\\\Zip_Codes.geojson'\n",
    "url = 'https://opendata.arcgis.com/datasets/83fc2e72903343aabff6de8cb445b81c_2.geojson'\n",
    "geofile = get_geofile(url)\n",
    "\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1.0 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.1 Rename Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.2 Data Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.4 Check NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.5 Fillout NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.6 Change Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.7 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2.0 FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.1 Hypothesis Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2.2 Final List of Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.2 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T01:09:26.957538Z",
     "start_time": "2021-04-06T01:09:26.951554Z"
    }
   },
   "outputs": [],
   "source": [
    "t = (1, 2, 3, [4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T01:09:40.836387Z",
     "start_time": "2021-04-06T01:09:40.827411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, [7, 5, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[3][0] = 7\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:58:03.024572Z",
     "start_time": "2021-04-06T18:58:03.018587Z"
    }
   },
   "outputs": [],
   "source": [
    "l = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T01:11:17.535518Z",
     "start_time": "2021-04-06T01:11:17.527540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, (1, 2, 3, [7, 5, 6])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:58:08.654040Z",
     "start_time": "2021-04-06T18:58:08.639080Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reduce'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1f6d0e5314ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reduce'"
     ]
    }
   ],
   "source": [
    "l.reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
